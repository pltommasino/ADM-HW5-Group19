{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6cf567",
   "metadata": {},
   "source": [
    "# Homework 5 - The eternal significance of publications and citations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fcc293",
   "metadata": {},
   "source": [
    "This project was carried out by Group 19 of Algorithmic Methods for Data Mining, consisting of:\n",
    "\n",
    "| NAME and SURNAME | EMAIL |\n",
    "| --- | --- |\n",
    "| Pasquale Luca Tommasino | pl.tommasino@gmail.com | \n",
    "| Paolo Zilviano | zilviano.1916518@studenti.uniroma1.it |\n",
    "| | |\n",
    "| | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6c038",
   "metadata": {},
   "source": [
    "## 1. Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611fcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import ijson\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd8d36",
   "metadata": {},
   "source": [
    "At the first, let's see how the file is structured, let's take the first row of the dataset and see what the columns and the first row of the dataset are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14daa051",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dblp.v12.json', 'r') as file:\n",
    "    # Parse the JSON array items one by one\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    # Iterate over the JSON array items\n",
    "    for item in array_items:\n",
    "        dict1 = item\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559c93a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'authors', 'title', 'year', 'n_citation', 'page_start', 'page_end', 'doc_type', 'publisher', 'volume', 'issue', 'doi', 'references', 'indexed_abstract', 'fos', 'venue']\n"
     ]
    }
   ],
   "source": [
    "#List the column of the json file\n",
    "chiave = list(dict1.keys())\n",
    "print(chiave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec97c927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1091, [{'name': 'Makoto Satoh', 'org': 'Shinshu University', 'id': 2312688602}, {'name': 'Ryo Muramatsu', 'org': 'Shinshu University', 'id': 2482909946}, {'name': 'Mizue Kayama', 'org': 'Shinshu University', 'id': 2128134587}, {'name': 'Kazunori Itoh', 'org': 'Shinshu University', 'id': 2101782692}, {'name': 'Masami Hashimoto', 'org': 'Shinshu University', 'id': 2114054191}, {'name': 'Makoto Otani', 'org': 'Shinshu University', 'id': 1989208940}, {'name': 'Michio Shimizu', 'org': 'Nagano Prefectural College', 'id': 2134989941}, {'name': 'Masahiko Sugimoto', 'org': 'Takushoku University, Hokkaido Junior College', 'id': 2307479915}], 'Preliminary Design of a Network Protocol Learning Tool Based on the Comprehension of High School Students: Design by an Empirical Study Using a Simple Mind Map', 2013, 1, '89', '93', 'Conference', 'Springer, Berlin, Heidelberg', '', '', '10.1007/978-3-642-39476-8_19', [2005687710, 2018037215], {'IndexLength': 58, 'InvertedIndex': {'tool.': [42], 'study': [4], 'aim': [37], 'purpose': [1], 'scientific': [17], 'for': [11], 'aspects': [18], 'students': [14, 46], 'focus': [27], 'hands-on': [47], 'learning': [9, 41], 'experience': [48], 'our': [40], 'we': [26], 'network': [33, 56], 'The': [0], 'More': [24], 'high': [12], 'protocols.': [57], 'school': [13], 'and': [21], 'of': [2, 19, 32, 55], 'communication': [22], 'protocols': [34], 'gives': [45], 'on': [28], 'a': [8], 'studying': [15], 'specifically,': [25], 'this': [3], 'understand': [51], 'is': [5], 'develop': [7, 39], 'Our': [43], 'tool': [10, 44], 'the': [16, 29, 36, 52], 'help': [50], 'as': [35], 'principles': [31, 54], 'information': [20], 'networks.': [23], 'to': [6, 38, 49], 'basic': [30, 53]}}, [{'name': 'Telecommunications network', 'w': Decimal('0.45139')}, {'name': 'Computer science', 'w': Decimal('0.45245')}, {'name': 'Mind map', 'w': Decimal('0.5347')}, {'name': 'Human–computer interaction', 'w': Decimal('0.47011')}, {'name': 'Multimedia', 'w': Decimal('0.46629')}, {'name': 'Empirical research', 'w': Decimal('0.49737')}, {'name': 'Comprehension', 'w': Decimal('0.47042')}, {'name': 'Communications protocol', 'w': Decimal('0.51907')}], {'raw': 'International Conference on Human-Computer Interaction', 'id': 1127419992, 'type': 'C'}]\n"
     ]
    }
   ],
   "source": [
    "#List of values of first row of the json file\n",
    "valori = list(dict1.values())\n",
    "print(valori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b7f72",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ae8a3",
   "metadata": {},
   "source": [
    "We now transform the entire *.json file* into a dictionary with selected columns (*id, authors, title, year, n_citation, doc_type, publisher* and *references*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "323011fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dict for Collaboration Graph\n",
    "dict_entire = {\n",
    "    'id' : [], \n",
    "    'authors' : [], \n",
    "    'title' : [], \n",
    "    'year' : [], \n",
    "    'n_citation' : [], \n",
    "    'doc_type' : [], \n",
    "    'publisher' : [],\n",
    "    'references' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0be070",
   "metadata": {},
   "source": [
    "We create functions for processing the *.json file* (they are in **function.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62e02db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4894081it [05:59, 13614.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from function import *\n",
    "\n",
    "with open('dblp.v12.json', 'r') as file:\n",
    "    # Parse the JSON array items one by one\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    # Iterate over the JSON array items\n",
    "    for item in tqdm(array_items):\n",
    "        # Process each JSON array item as needed\n",
    "        dict_id(dict_entire, item)\n",
    "        dict_authors(dict_entire, item)\n",
    "        dict_title(dict_entire, item)\n",
    "        dict_year(dict_entire, item)\n",
    "        dict_n_citation(dict_entire, item)\n",
    "        dict_doc_type(dict_entire, item)\n",
    "        dict_publisher(dict_entire, item)\n",
    "        dict_references(dict_entire, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639ec06",
   "metadata": {},
   "source": [
    "Transform dictionary in Pandas Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb0d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>publisher</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1091</td>\n",
       "      <td>[Makoto Satoh, Ryo Muramatsu, Mizue Kayama, Ka...</td>\n",
       "      <td>Preliminary Design of a Network Protocol Learn...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Springer, Berlin, Heidelberg</td>\n",
       "      <td>[2005687710, 2018037215]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388</td>\n",
       "      <td>[Pranava K. Jha]</td>\n",
       "      <td>Further Results on Independence in Direct-Prod...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Journal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1674</td>\n",
       "      <td>[G. Beale, G. Earl]</td>\n",
       "      <td>A methodology for the physically accurate visu...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Eurographics Association</td>\n",
       "      <td>[1535888970, 1992876689, 1993710814, 203565334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1688</td>\n",
       "      <td>[Altaf Hossain, Faisal Zaman, M. Nasser, M. Mu...</td>\n",
       "      <td>Comparison of GARCH, Neural Network and Suppor...</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Springer, Berlin, Heidelberg</td>\n",
       "      <td>[1560724230, 1986968751, 2156909104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>[Rafael Álvarez, Leandro Tortosa, José-Francis...</td>\n",
       "      <td>COMPARING GNG3D AND QUADRIC ERROR METRICS METH...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>Conference</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                            authors  \\\n",
       "0  1091  [Makoto Satoh, Ryo Muramatsu, Mizue Kayama, Ka...   \n",
       "1  1388                                   [Pranava K. Jha]   \n",
       "2  1674                                [G. Beale, G. Earl]   \n",
       "3  1688  [Altaf Hossain, Faisal Zaman, M. Nasser, M. Mu...   \n",
       "4  5411  [Rafael Álvarez, Leandro Tortosa, José-Francis...   \n",
       "\n",
       "                                               title  year  n_citation  \\\n",
       "0  Preliminary Design of a Network Protocol Learn...  2013           1   \n",
       "1  Further Results on Independence in Direct-Prod...  2000           1   \n",
       "2  A methodology for the physically accurate visu...  2011           1   \n",
       "3  Comparison of GARCH, Neural Network and Suppor...  2009           6   \n",
       "4  COMPARING GNG3D AND QUADRIC ERROR METRICS METH...  2009           0   \n",
       "\n",
       "     doc_type                     publisher  \\\n",
       "0  Conference  Springer, Berlin, Heidelberg   \n",
       "1     Journal                          None   \n",
       "2  Conference      Eurographics Association   \n",
       "3  Conference  Springer, Berlin, Heidelberg   \n",
       "4  Conference                          None   \n",
       "\n",
       "                                          references  \n",
       "0                           [2005687710, 2018037215]  \n",
       "1                                               None  \n",
       "2  [1535888970, 1992876689, 1993710814, 203565334...  \n",
       "3               [1560724230, 1986968751, 2156909104]  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform dict in dataframe\n",
    "df_entire = pd.DataFrame(dict_entire)\n",
    "df_entire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81fe7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save df in csv file\n",
    "#df_entire.to_csv('df_entire.csv')\n",
    "#Read csv df file\n",
    "#df_entire = pd.read_csv('df_entire.csv', index_col=0, low_memory=False)\n",
    "\n",
    "#Drop NaN value in the column I\n",
    "#df_entire = df_entire.dropna(subset='id')\n",
    "\n",
    "#Transform columns from decimal to integer\n",
    "#df_entire['id'] = df_entire['id'].astype(int)\n",
    "#df_entire['n_citation'] = df_entire['n_citation'].astype(int)\n",
    "#Transform column from integer to datetime (year)\n",
    "#df_entire['year'] = df_entire['year'].astype('datetime64[Y]')\n",
    "\n",
    "#See the 'head' of dataset\n",
    "#df_entire.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bca0d8",
   "metadata": {},
   "source": [
    "#### 1. Identify the top 10,000 papers with the highest number of citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae167f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>publisher</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4696136</th>\n",
       "      <td>2041404167</td>\n",
       "      <td>[C. E. Shannon]</td>\n",
       "      <td>The Mathematical Theory of Communication</td>\n",
       "      <td>1949</td>\n",
       "      <td>48327</td>\n",
       "      <td>Book</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630907</th>\n",
       "      <td>1639032689</td>\n",
       "      <td>[David E. Goldberg]</td>\n",
       "      <td>Genetic algorithms in search, optimization, an...</td>\n",
       "      <td>1989</td>\n",
       "      <td>44175</td>\n",
       "      <td>Book</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092588</th>\n",
       "      <td>2912565176</td>\n",
       "      <td>[Lotfi A. Zadeh]</td>\n",
       "      <td>Fuzzy sets</td>\n",
       "      <td>1996</td>\n",
       "      <td>42437</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937610</th>\n",
       "      <td>2151103935</td>\n",
       "      <td>[David G. Lowe]</td>\n",
       "      <td>Distinctive Image Features from Scale-Invarian...</td>\n",
       "      <td>2004</td>\n",
       "      <td>35541</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Kluwer Academic Publishers</td>\n",
       "      <td>[19720318, 1541642243, 1560959218, 1676552347,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088311</th>\n",
       "      <td>2911964244</td>\n",
       "      <td>[Leo Breiman]</td>\n",
       "      <td>Random Forests</td>\n",
       "      <td>2001</td>\n",
       "      <td>34741</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[1507255258, 1580948147, 1605688901, 197584664...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              authors  \\\n",
       "4696136  2041404167      [C. E. Shannon]   \n",
       "4630907  1639032689  [David E. Goldberg]   \n",
       "4092588  2912565176     [Lotfi A. Zadeh]   \n",
       "2937610  2151103935      [David G. Lowe]   \n",
       "4088311  2911964244        [Leo Breiman]   \n",
       "\n",
       "                                                     title  year  n_citation  \\\n",
       "4696136           The Mathematical Theory of Communication  1949       48327   \n",
       "4630907  Genetic algorithms in search, optimization, an...  1989       44175   \n",
       "4092588                                         Fuzzy sets  1996       42437   \n",
       "2937610  Distinctive Image Features from Scale-Invarian...  2004       35541   \n",
       "4088311                                     Random Forests  2001       34741   \n",
       "\n",
       "        doc_type                   publisher  \\\n",
       "4696136     Book                        None   \n",
       "4630907     Book                        None   \n",
       "4092588     None                        None   \n",
       "2937610  Journal  Kluwer Academic Publishers   \n",
       "4088311     None                        None   \n",
       "\n",
       "                                                references  \n",
       "4696136                                               None  \n",
       "4630907                                               None  \n",
       "4092588                                               None  \n",
       "2937610  [19720318, 1541642243, 1560959218, 1676552347,...  \n",
       "4088311  [1507255258, 1580948147, 1605688901, 197584664...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the top 10000 papers with the highest number of citations\n",
    "df_10th_papers = df_entire.sort_values(by=['n_citation'], ascending=False)[:10000]\n",
    "\n",
    "#See the first five lines\n",
    "df_10th_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9db47c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save df in csv file\n",
    "#df_10th_papers.to_csv('df_10th_papers.csv')\n",
    "#Read csv df file\n",
    "#df_10th_papers = pd.read_csv('df_10th_papers.csv')\n",
    "\n",
    "#Transform columns from decimal to integer\n",
    "#df_10th_papers['id'] = df_10th_papers['id'].astype(int)\n",
    "#df_10th_papers['n_citation'] = df_10th_papers['n_citation'].astype(int)\n",
    "#Transform column from integer to datetime (year)\n",
    "#df_10th_papers['year'] = df_10th_papers['year'].astype('datetime64[Y]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf14f33",
   "metadata": {},
   "source": [
    "#### 2. Then the nodes of your graphs would be as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a48f48",
   "metadata": {},
   "source": [
    "#### - **Citation graph**: you can consider each of the papers as your nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16733d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chech if in the column 'id' there are any NaN value in column\n",
    "isthere_nan = df_entire['id'].isna().any()\n",
    "isthere_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6150f2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1091, 1388, 1674, 1688, 5411]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create nodes for Citation Graph\n",
    "citationG_nodes = dict_entire['id']\n",
    "citationG_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2483b51f",
   "metadata": {},
   "source": [
    "#### - **Collaboration graph**: the authors of these papers would be your nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "277eac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chech if in the column 'authors' there are any NaN value in column\n",
    "isthere_nan = df_entire['authors'].isna().any()\n",
    "isthere_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cb80421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entire = df_entire.dropna(subset='authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e47bca44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Makoto Satoh',\n",
       " 'Ryo Muramatsu',\n",
       " 'Mizue Kayama',\n",
       " 'Kazunori Itoh',\n",
       " 'Masami Hashimoto']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create nodes for Collaboration Graph\n",
    "collaborationG_nodes_2 = df_entire['authors']\n",
    "\n",
    "#Unzip the nested lists in one list of authors\n",
    "collaborationG_nodes = []\n",
    "\n",
    "for list_1 in collaborationG_nodes_2:\n",
    "    for author in list_1:\n",
    "        collaborationG_nodes.append(author)\n",
    "\n",
    "collaborationG_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f69c4f",
   "metadata": {},
   "source": [
    "#### 3. For the edges of the two graphs, you would have the following cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e7795",
   "metadata": {},
   "source": [
    "#### - **Citation graph**: only consider the citation relationship between these 10,000 papers and ignore the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7546adcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2151103935, 19720318),\n",
       " (2151103935, 1541642243),\n",
       " (2151103935, 1560959218),\n",
       " (2151103935, 1676552347),\n",
       " (2151103935, 1681491849)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a subset of the 10,000 papers dataset, and transform it in a readable dataset...\n",
    "##... with only two column, within one value\n",
    "citationG_edges_df_2 = df_10th_papers.reset_index()[['id','references']]\n",
    "citationG_edges_df_2 = citationG_edges_df_2.explode('references')\n",
    "citationG_edges_df_2 = citationG_edges_df_2.dropna(subset=['references']).reset_index()[['id','references']]\n",
    "\n",
    "#Transform dataset in a list of tuple\n",
    "citationG_edges = [tuple(x) for x in citationG_edges_df_2.to_records(index=False)]\n",
    "citationG_edges[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83969ee",
   "metadata": {},
   "source": [
    "#### - **Collaboration graph**: only consider the collaborations between the authors of these 10,000 papers and ignore the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1574a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collaboration_dict = {\n",
    "    'name1' : [],\n",
    "    'name2' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9383d665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('David W. Hosmer', 'Stanley Lemeshow'),\n",
       " ('Chih-Chung Chang', 'Chih-Jen Lin'),\n",
       " ('Corinna Cortes', 'Vladimir Vapnik'),\n",
       " ('Heng Li', 'Richard Durbin'),\n",
       " ('K. Deb', 'A. Pratap')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a subset of the 10,000 papers dataset, and transform it in a readable dataset...\n",
    "##... with only two column, within one value\n",
    "collaborationG_edges_df_2 = df_10th_papers.reset_index()[['authors']]\n",
    "nestedlist_auth_collaboration = collaborationG_edges_df_2['authors'].tolist()\n",
    "\n",
    "#Create all possible matches of collaboration for each book\n",
    "collaborationG_edges = []\n",
    "for authors_list in nestedlist_auth_collaboration:\n",
    "    for i in range(len(authors_list)):\n",
    "        for j in range(i + 1, len(authors_list)):\n",
    "            collaborationG_edges.append((authors_list[i], authors_list[j]))\n",
    "\n",
    "collaborationG_edges[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4eeca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a counter for couple\n",
    "collaborationG_edges_counter = Counter(collaborationG_edges)\n",
    "\n",
    "#Create a dictionary for track couple weight\n",
    "collaborationG_edges_weights = {}\n",
    "\n",
    "#Iteract edges and count from dict\n",
    "for edge, count in collaborationG_edges_counter.items():\n",
    "    collaborationG_edges_weights[edge] = count\n",
    "\n",
    "    #Add weight also for inverted edge\n",
    "    inverted_edge = (edge[1], edge[0])\n",
    "    collaborationG_edges_weights[inverted_edge] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305de48",
   "metadata": {},
   "source": [
    "#### Now we calculate the graphs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd61e7",
   "metadata": {},
   "source": [
    "#### - **Citation graph**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17676411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a unweighted and directed graph\n",
    "citation_graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "citation_graph.add_nodes_from(citationG_nodes)\n",
    "# Add edges to the graph\n",
    "citation_graph.add_edges_from(citationG_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd0764f",
   "metadata": {},
   "source": [
    "#### - **Collaboration graph**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61fc7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a weighted and undirected graph\n",
    "collaboration_graph = nx.Graph()\n",
    "\n",
    "#Add nodes to the graph\n",
    "collaboration_graph.add_nodes_from(collaborationG_nodes)\n",
    "\n",
    "#Add edges to the graph\n",
    "for edge, weight in collaborationG_edges_weights.items():\n",
    "    collaboration_graph.add_edge(edge[0], edge[1], weight=weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b8cd7",
   "metadata": {},
   "source": [
    "## 2. Controlling system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd925e2b",
   "metadata": {},
   "source": [
    "### 2.1 Backend Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c83db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this section (2.1) we work with the subgraph (10,000) of the entire graph\n",
    "\n",
    "#Shortlist for Citation Subgraph\n",
    "books_red = df_10th_papers['id'].tolist()\n",
    "#Subgraph\n",
    "sub_citation_graph = citation_graph.subgraph(books_red)\n",
    "\n",
    "#Create the shortlist for Collaboration Subgraph\n",
    "auth_red = []\n",
    "for list_2 in nestedlist_auth_collaboration:\n",
    "    for auth in list_2:\n",
    "        auth_red.append(auth)\n",
    "#Subgraph\n",
    "sub_collaboration_graph = collaboration_graph.subgraph(auth_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5c63ca",
   "metadata": {},
   "source": [
    "#### Functionality 1 - Graph's features\n",
    "\n",
    "**Input**:\n",
    "- The graph\n",
    "- The name of the graph\n",
    "\n",
    "**Output**:\n",
    "- The number of the nodes in the graph\n",
    "- The number of the edges in the graph\n",
    "- The graph density\n",
    "- The graph degree distribution\n",
    "- The average degree of the graph\n",
    "- The graph hubs (hubs are nodes having degrees more extensive than the 95th percentile of the degree distribution)\n",
    "- Whether the graph is dense or sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a38c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend import *\n",
    "\n",
    "name_graph = 'Sub Citation Graph'\n",
    "len_nodes_citation, len_edges_citation, density_citation, degree_sequence_citation, avg_degree_citation, hubs_citation, classification_graph_citation = functionality_1(sub_citation_graph, name_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9e29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend import functionality_1\n",
    "\n",
    "name_graph = 'Sub Collaboration Graph'\n",
    "len_nodes_collab, len_edges_collab, density_collab, degree_sequence_collab, avg_degree_collab, hubs_collab, classification_graph_collab = functionality_1(sub_collaboration_graph, name_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5fb431",
   "metadata": {},
   "source": [
    "#### Functionality 2 - Nodes' contribution\n",
    "\n",
    "##### Input:\n",
    "- The graph\n",
    "- A node of the graph (paper/author)\n",
    "- The name of the graph\n",
    "\n",
    "##### Output:\n",
    "\n",
    "- The centrality of the node, calculated based on the following centrality measurements:\n",
    "    - Betweeness\n",
    "    - PageRank\n",
    "    - ClosenessCentrality\n",
    "    - DegreeCentrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a0f7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend import functionality_2\n",
    "\n",
    "#node_selected_collaboration = 2155511848\n",
    "\n",
    "name_graph = 'Sub Citation Graph'\n",
    "#node_selected = int(input(\"Insert the Node that the function calculated: \"))\n",
    "betw, pagerank, closeness, degree = functionality_2(sub_citation_graph, node_selected=2155511848, name_graph=name_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccc51e",
   "metadata": {},
   "source": [
    "#### Functionality 3 - Shortest ordered walk\n",
    "\n",
    "##### Input:\n",
    "- The graph data\n",
    "- A sequence of authors_a = [a_2, ..., a_{n-1}]\n",
    "- Initial node a_1 and an end node a_n\n",
    "- *N*: denoting the top *N* authors whose data should be considered\n",
    "\n",
    "##### Output:\n",
    "- The shortest walk of collaborations you need to read to get from author a_1 to author a_n and the papers you need to cross to realize this walk.\n",
    "\n",
    "\n",
    "Considerations: \n",
    "For this functionality, you must implement an algorithm that returns the shortest __walk__ that goes from node a\\_j to a\\_n, which visits **in order** the nodes in _a_. The choice of a\\_j and a\\_n can be made randomly (or if it improves the performance of the algorithm, you can also define it in any other way) \n",
    "\n",
    "__Important Notes:__\n",
    "- This algorithm should be run only on the collaboration graph.\n",
    "- The algorithm needs to handle the case that the graph is not connected. Thus, only some nodes in _a_ are reachable from a\\_1. In such a scenario, it is enough to let the program give in the output the string \"There is no such path.\"\n",
    "- Since we are dealing with walks, you can pass on the same node _a\\_i_ more than once, but you must preserve order. It means you can go back to any author node any time you want, assuming that the order in which you visit the required nodes is still the same.\n",
    "- Once you completed your implementation, ask chatGPT for a different one leveraging another approach in solving the shortest path and prove whether this implementation is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6b0fe1",
   "metadata": {},
   "source": [
    "PROVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6389f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_for_topN = dict(collaboration_graph.degree())\n",
    "topN_auth_2 = sorted(degrees_for_topN.items(), key=lambda x:x[1], reverse=True)[:100]\n",
    "topN_auth = [i[0] for i in topN_auth_2] #taken\n",
    "Nauthors_graph = collaboration_graph.subgraph(topN_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1642de5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 155\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shortest_walk\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m#from backend import functionality_3_prova\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m shortest_walk \u001b[38;5;241m=\u001b[39m functionality_3_prova3(collaboration_graph, sequence_authors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, node_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, node_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    156\u001b[0m shortest_walk\n",
      "Cell \u001b[0;32mIn[49], line 136\u001b[0m, in \u001b[0;36mfunctionality_3_prova3\u001b[0;34m(graph, sequence_authors, node_first, node_last, N)\u001b[0m\n\u001b[1;32m    133\u001b[0m shortest_walk \u001b[38;5;241m=\u001b[39m []\u001b[38;5;241m.\u001b[39mappend(node_first)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# shortest path between starting node and first node in the sequence\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m path \u001b[38;5;241m=\u001b[39m Dijkstra(Nauthors_graph, node_first, sequence_authors)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# add to total path (without repeating starting node)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m shortest_walk\u001b[38;5;241m.\u001b[39mextend(path[\u001b[38;5;241m1\u001b[39m:])\n",
      "Cell \u001b[0;32mIn[49], line 78\u001b[0m, in \u001b[0;36mDijkstra\u001b[0;34m(graph, node_start, sequence_authors)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m [z, w] \u001b[38;5;129;01min\u001b[39;00m V:\n\u001b[1;32m     77\u001b[0m     d \u001b[38;5;241m=\u001b[39m dist[i] \u001b[38;5;241m+\u001b[39m w\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dist[z] \u001b[38;5;241m>\u001b[39m d:\n\u001b[1;32m     79\u001b[0m         dist[z] \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m     80\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Dijkstra's algorithm\n",
    "def NextNode(dist, visited):\n",
    "    \n",
    "    ---\n",
    "    Found the next node to operate on\n",
    "    ---\n",
    "\n",
    "    Input:\n",
    "    - dist: list of distances\n",
    "    - visited: list of all nodes if the node is visited (=True), not visited (=False)\n",
    "    Output:\n",
    "    - next_node: next node to operate on\n",
    "    \n",
    "\n",
    "    min = float('inf')\n",
    "    next_node = -1\n",
    "    for i in range(len(dist)):\n",
    "        if (not visited[i]) and (dist[i] < min):\n",
    "            next_node = i\n",
    "            min = dist[i]\n",
    "    return next_node\n",
    "'''\n",
    "\n",
    "def getAdjacents(graph, actual_node, next_node):\n",
    "    '''\n",
    "    ---\n",
    "    Found the list of nodes adjacent to the node selected\n",
    "    ---\n",
    "\n",
    "    Input:\n",
    "    - graph: graph\n",
    "    - node: node of graph\n",
    "    Output:\n",
    "    - list_nodes_adjacent: list of nodes adjacent to the node\n",
    "    '''\n",
    "\n",
    "    #list_nodes_adjacent = []\n",
    "    auth = [i for i in graph[actual_node]]\n",
    "    weight_auth = [graph[actual_node][i]['weight'] for i in auth]\n",
    "    nod_adj = list(zip(auth, weight_auth))\n",
    "    '''\n",
    "    for j in range(len(graph)):\n",
    "        if nod_adj[1][1] != float('inf'):\n",
    "            list_nodes_adjacent.append(nod_adj[j])\n",
    "            '''\n",
    "    return nod_adj #list_nodes_adjacent\n",
    "\n",
    "def Dijkstra(graph, node_start, sequence_authors):\n",
    "    '''\n",
    "    Input:\n",
    "    - graph\n",
    "    - node_start: start node to calculate minimum distances\n",
    "    - authors_sequence: list of authors to consider\n",
    "    Output:\n",
    "    - dist: list of distances\n",
    "    '''\n",
    "\n",
    "    start = 1\n",
    "    n = len(graph)\n",
    "\n",
    "    dict_grafo = {\n",
    "        'index': [],\n",
    "        'name_node': [],\n",
    "        'visited': [],\n",
    "        'dist': []\n",
    "    }\n",
    "\n",
    "    for i in range(n):\n",
    "        dict_grafo['index'].append(i)\n",
    "        dict_grafo['visited'].append(False)\n",
    "        dict_grafo['dist'].append(float('inf'))\n",
    "\n",
    "    dict_grafo[dict_grafo['visited'] == node_start]\n",
    "\n",
    "    if start == 1:\n",
    "        actual = node_start\n",
    "        next = sequence_authors[0]\n",
    "        V = getAdjacents(graph, actual, next)\n",
    "        for [z, w] in V:\n",
    "            index_actual = name_node\n",
    "            d = dist[0] + w\n",
    "            if dist[z] > d:\n",
    "                dist[z] = d\n",
    "        start = 0\n",
    "    else:\n",
    "        for i in range(n - 1):\n",
    "            #next = NextNode(dist, visited)\n",
    "            next = sequence_authors[i]\n",
    "            visited[i] = True\n",
    "            V = getAdjacents(graph, next)\n",
    "            for [z, w] in V:\n",
    "                d = dist[i] + w\n",
    "                if dist[z] > d:\n",
    "                    dist[z] = d\n",
    "\n",
    "    return dist\n",
    "\n",
    "def functionality_3_prova3(graph, sequence_authors, node_first, node_last, N):\n",
    "    '''\n",
    "    Input:\n",
    "    - graph: The graph data\n",
    "    - sequence_authors: A sequence of authors_a = [a_2, ..., a_{n-1}] (put 0 for a sample)\n",
    "    - node_first: Initial node a_1 (put 0 for a take the first in the sample)\n",
    "    - node_last: End node a_n (put 0 for a take the last in the sample)\n",
    "    - N: denoting the top N authors whose data should be considered\n",
    "\n",
    "    Output:\n",
    "    - shortest_walk: The shortest walk of collaborations you need to read to get from author a_1 to author a_n\n",
    "    - papers: The papers you need to cross to realize this walk.\n",
    "    '''\n",
    "\n",
    "    #Create a sub-graph from N (the top N authors with the highest degree)\n",
    "    degrees_for_topN = dict(graph.degree())\n",
    "    topN_auth_2 = sorted(degrees_for_topN.items(), key=lambda x:x[1], reverse=True)[:N]\n",
    "    topN_auth = [i[0] for i in topN_auth_2] #taken\n",
    "    Nauthors_graph = graph.subgraph(topN_auth)\n",
    "\n",
    "    if sequence_authors==0:\n",
    "        #Extract all the nodes a take a sample from this\n",
    "        n = 10\n",
    "        all_authors = list(Nauthors_graph.nodes)\n",
    "        sequence_authors = random.sample(all_authors, n)\n",
    "    \n",
    "    if node_first==0:\n",
    "        #Select the first...\n",
    "        node_first = sequence_authors[0]\n",
    "        #... and delete it from sequence authors\n",
    "        sequence_authors.remove(node_first)\n",
    "\n",
    "    if node_last==0:\n",
    "        #Select the last...\n",
    "        node_last = sequence_authors[-1]\n",
    "        #... and delete it from sequence authors\n",
    "        sequence_authors.remove(node_last)\n",
    "\n",
    "    # final path\n",
    "    shortest_walk = [].append(node_first)\n",
    "\n",
    "    # shortest path between starting node and first node in the sequence\n",
    "    path = Dijkstra(Nauthors_graph, node_first, sequence_authors)\n",
    "    # add to total path (without repeating starting node)\n",
    "    shortest_walk.extend(path[1:])\n",
    "\n",
    "    # for each node in the sequence\n",
    "    # find shortest path between that node and the following node in the sequence\n",
    "    for p in range((len(sequence_authors)-1)):\n",
    "      path = Dijkstra(Nauthors_graph, sequence_authors[p], sequence_authors[p+1])[0] \n",
    "      # add path to total_path\n",
    "      shortest_walk.extend(path[1:])\n",
    "\n",
    "    # shortest path between last node in the sequence and ending node\n",
    "    path = Dijkstra(Nauthors_graph, sequence_authors[-1], node_last)[0]\n",
    "    shortest_walk.extend(path[1:])\n",
    "\n",
    "    return shortest_walk\n",
    "\n",
    "#from backend import functionality_3_prova\n",
    "\n",
    "shortest_walk = functionality_3_prova3(collaboration_graph, sequence_authors=0, node_first=0, node_last=0, N=100)\n",
    "shortest_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c48219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from backend import functionality_3_prova\n",
    "\n",
    "shortest_walk = functionality_3_prova3(collaboration_graph, sequence_authors=0, node_first=0, node_last=0, N=100)\n",
    "shortest_walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c543ba32",
   "metadata": {},
   "source": [
    "VERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend import functionality_3\n",
    "\n",
    "#We selected N = 1000\n",
    "N_sel = 100\n",
    "\n",
    "#shortest_walk, papers = functionality_3(collaboration_graph, sequence_authors=0, node_first=0, node_last=0, N=N_sel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35e14b",
   "metadata": {},
   "source": [
    "#### Functionality 4 - Disconnecting Graphs\n",
    "\n",
    "##### Input:\n",
    "\n",
    "- The graph data\n",
    "- authorA: a paper to which will relate sub-graph G_a\n",
    "- authorB: a paper to which will relate sub-graph G_b\n",
    "- *N*: denoting the top *N* authors that their data should be considered\n",
    "\n",
    "##### Output:\n",
    "\n",
    "- The minimum number of edges (by considering their weights) required to disconnect the original graph in two disconnected subgraphs: G_a and G_b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cafd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from backend import functionality_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc496c69",
   "metadata": {},
   "source": [
    "#### Functionality 5 - Extracting Communities\n",
    "\n",
    "##### Input:\n",
    "\n",
    "- The graph data\n",
    "- *N*: denoting the top *N* papers that their data should be considered\n",
    "- Paper_1: denoting the name of one of the papers\n",
    "- Paper_2: denoting the name of one of the papers\n",
    "\n",
    "##### Output:\n",
    "\n",
    "- The minimum number of edges that should be removed to form communities\n",
    "- A list of communities, each containing a list of papers that belong to them.\n",
    "- Whether the Paper_1 and Paper_2 belongs to the same community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend import functionality_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373421c4",
   "metadata": {},
   "source": [
    "### 2.2. Frontend Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503b626",
   "metadata": {},
   "source": [
    "## 3. Bonus - PageRank on MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162046cd",
   "metadata": {},
   "source": [
    "## 4. Command Line Question (CLQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b626a",
   "metadata": {},
   "source": [
    "## 5. Algorithmic Question (AQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
